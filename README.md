# PanelFM

Time series foundation models for per-member per-month (PMPM) cost prediction in Medicaid managed care, evaluated against actuarial risk adjustment benchmarks.

## Overview

This repository contains the code for the paper:

> **Time Series Foundation Models for Per-Member Per-Month Cost Prediction: Prospective and Concurrent Evaluation Against Actuarial Benchmarks in Medicaid Claims**
>
> Sanjay Basu, Aaron Baum, Sadiq Patel

The study evaluates 22 models across five categories (cross-sectional ML, time series baselines, a pretrained foundation model, hybrid models, and concurrent models) on deidentified Medicaid managed care claims data from 122,849 members contributing 2.4 million patient-months.

## Repository Structure

```
panelfm/
  configs/                  # Experiment and data configuration
    data_config.yaml        # Data source paths and column mappings
    experiment_config.yaml  # Experiment parameters
    model_config.yaml       # Model hyperparameters
  scripts/
    run_experiment.py               # Main experiment runner (all models)
    generate_publication_tables.py  # Bootstrap CIs, statistical tests, actuarial tables
    generate_final_figures.py       # Publication figures
  src/
    data/
      load_claims.py        # Claims data loading, feature engineering, temporal splits
      synthetic_panel.py    # Synthetic panel data generation (Section S1)
    evaluation/
      metrics.py            # Actuarial metrics: calibrated R^2, predictive ratios, decile analysis
    models/
      baselines.py          # Cross-sectional models: XGBoost, RF, LightGBM, TwoPartModel, DemographicGLM
      ts_baselines.py       # Time series baselines: naive, ARIMA
      timesfm_wrapper.py    # Chronos foundation model + PanelFM conditioning strategies
      patient_encoder.py    # XGBoost leaf-node embeddings + PCA
  paper/                    # Manuscript, appendix, cover letter, figures
  results/                  # Generated outputs (not committed)
  requirements.txt
```

## Reproducing Results

### Prerequisites

```bash
pip install -r requirements.txt
```

Python 3.12 was used for all experiments. The Chronos model checkpoint (`amazon/chronos-t5-small`) is downloaded automatically from Hugging Face on first run.

### Data Setup

The experiment requires deidentified Medicaid claims data in CSV format. Set the `DATA_ROOT` environment variable to point to your data directory, or place files under `./data/real_inputs/`. Required files are listed in `configs/data_config.yaml`.

The synthetic data experiment runs without any external data:

```bash
# Runs both synthetic and real data experiments
python scripts/run_experiment.py
```

If real data is unavailable, the synthetic experiment completes and the real data experiment fails gracefully.

### Running the Full Pipeline

```bash
# 1. Run all models (synthetic + real data)
python scripts/run_experiment.py

# 2. Generate publication tables (bootstrap CIs, statistical tests)
python scripts/generate_publication_tables.py

# 3. Generate publication figures
python scripts/generate_final_figures.py
```

Total runtime is approximately 2 hours on a single CPU workstation, dominated by Chronos inference on the full 64,141-patient test set.

### Output

Results are saved to `results/`:
- `all_metrics_{synthetic,real}.json` — aggregate metrics for all models
- `per_patient_data_{synthetic,real}.json` — per-patient predictions for bootstrap CIs
- Actuarial summary tables, decile analysis, and statistical tests (generated by `generate_publication_tables.py`)
- Figures 1-3 (generated by `generate_final_figures.py`)

## Models

| Category | Models | Section |
|---|---|---|
| Cross-sectional ML | XGBoost, Random Forest, LightGBM, Stacking Ensemble, Two-Part Model | S2 |
| Demographics-only | GLM (age, sex, dual-eligible) | Actuarial floor |
| Time series | Naive trailing mean, Naive last-value, ARIMA | S3 |
| Foundation model | Chronos-T5-Small (46M params, zero-shot) | S3.3 |
| PanelFM variants | XReg (linear), Adapter (MLP, 1,475 params), ICF (kNN context) | S4-S5 |
| Hybrid | TS temporal pattern + calibrated CS patient-level budget | S9 |
| Concurrent | Same-period features (XGBoost, RF, LightGBM, Two-Part, GLM) | S8.6 |

## Evaluation Metrics

Following Society of Actuaries (SOA) and CMS risk adjustment standards:
- Calibrated R-squared (budget-neutral)
- Predictive ratios (target: 0.90-1.10)
- Decile analysis
- Cost-censored R-squared ($250K cap)
- C-statistic for high-cost identification
- Mean absolute error with bootstrap 95% CIs

## License

This code is provided for research purposes. See the manuscript for full methodological details.
